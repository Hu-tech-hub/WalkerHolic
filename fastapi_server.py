#!/usr/bin/env python3
"""
Gait Analysis FastAPI Server
ë°±ì—”ë“œ ë˜í•‘ ê°€ì´ë“œì— ë§ì¶˜ ë¹„ë™ê¸° ì§„ë‹¨ API ì„œë²„

Requirements:
- POST /gait-analysis/langgraph-diagnosis: ì§„ë‹¨ ì‹œì‘
- GET /gait-analysis/diagnosis/status/{diagnosisId}: ìƒíƒœ í™•ì¸
- ê¸°ì¡´ test_optimized_nodes_pipeline() ê²°ê³¼ë¥¼ result í•„ë“œë¡œ ë˜í•‘

Author: AI Assistant
Date: 2025-01-18
"""

import os
import uuid
import asyncio
import concurrent.futures
import time
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, Any, Optional
from pathlib import Path
import threading
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
import uvicorn

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
import sys
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# ë­ê·¸ë˜í”„ ë…¸ë“œ imports (ìµœì¢… ë°°í¬ìš©)
from langgraph_nodes.graph_state import GraphState
from langgraph_nodes.data_processing_nodes import ReceiveRequestNode, FileMetadataNode, DownloadCsvNode, FilterDataNode
from langgraph_nodes.ai_model_nodes import PredictPhasesNode, PredictStrideNode
from langgraph_nodes.metrics_nodes import CalcMetricsNode, StoreMetricsNode
from langgraph_nodes.rag_diagnosis_nodes import ComposePromptNode, RagDiagnosisNode, StoreDiagnosisNode
from langgraph_nodes.response_nodes import FormatResponseNode

# ===== ê¸€ë¡œë²Œ ë…¸ë“œ ì¸ìŠ¤í„´ìŠ¤ (ìŠ¤ë§ˆíŠ¸ ì´ˆê¸°í™” ì‹œìŠ¤í…œ) =====
print("ğŸ”§ ì„œë²„ ì¤€ë¹„ ì¤‘...")

# ì´ˆê¸°í™” ìƒíƒœ íŒŒì¼ ê²½ë¡œ
INITIALIZATION_FILE = Path(__file__).parent / ".nodes_initialized"

# ë…¸ë“œ ì¸ìŠ¤í„´ìŠ¤ë“¤ì„ Noneìœ¼ë¡œ ì´ˆê¸°í™”
receive_request_node = None
file_metadata_node = None
download_csv_node = None
filter_data_node = None
predict_phases_node = None
predict_stride_node = None
calc_metrics_node = None
store_metrics_node = None
compose_prompt_node = None
rag_diagnosis_node = None
store_diagnosis_node = None
format_response_node = None

# ì´ˆê¸°í™” ì™„ë£Œ í”Œë˜ê·¸
_nodes_initialized = False
_initialization_lock = threading.Lock()

def is_already_initialized() -> bool:
    """ì´ì „ì— ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
    if not INITIALIZATION_FILE.exists():
        return False
    
    try:
        # íŒŒì¼ì´ 24ì‹œê°„ ì´ë‚´ì— ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸ (ë„ˆë¬´ ì˜¤ë˜ëœ ì´ˆê¸°í™”ëŠ” ë¬´íš¨)
        file_age = time.time() - INITIALIZATION_FILE.stat().st_mtime
        if file_age > 24 * 3600:  # 24ì‹œê°„
            print("ğŸ”„ ì´ˆê¸°í™” íŒŒì¼ì´ ì˜¤ë˜ë˜ì–´ ì¬ì´ˆê¸°í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            INITIALIZATION_FILE.unlink()  # ì˜¤ë˜ëœ íŒŒì¼ ì‚­ì œ
            return False
        
        return True
    except Exception:
        return False

def mark_initialization_complete():
    """ì´ˆê¸°í™” ì™„ë£Œ ìƒíƒœë¥¼ íŒŒì¼ì— ì €ì¥"""
    try:
        INITIALIZATION_FILE.write_text(f"initialized_at:{time.time()}\n")
        print(f"âœ… ì´ˆê¸°í™” ìƒíƒœ ì €ì¥: {INITIALIZATION_FILE}")
    except Exception as e:
        print(f"âš ï¸ ì´ˆê¸°í™” ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {e}")

def initialize_nodes_startup():
    """ì„œë²„ ì‹œì‘ì‹œ ë…¸ë“œ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ)"""
    global _nodes_initialized
    global receive_request_node, file_metadata_node, download_csv_node, filter_data_node
    global predict_phases_node, predict_stride_node, calc_metrics_node, store_metrics_node
    global compose_prompt_node, rag_diagnosis_node, store_diagnosis_node, format_response_node
    
    # ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if is_already_initialized():
        print("âš¡ ì´ì „ ì´ˆê¸°í™” ê°ì§€ - ë¹ ë¥¸ ì‹œì‘ ëª¨ë“œ")
        print("ğŸ”§ ë…¸ë“œ ì¸ìŠ¤í„´ìŠ¤ ë¹ ë¥¸ ì´ˆê¸°í™” ì¤‘...")
        
        # ë¹ ë¥¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (RAGëŠ” ì´ë¯¸ ì¤€ë¹„ë¨)
        receive_request_node = ReceiveRequestNode()
        file_metadata_node = FileMetadataNode()
        download_csv_node = DownloadCsvNode()
        filter_data_node = FilterDataNode()
        predict_phases_node = PredictPhasesNode()
        predict_stride_node = PredictStrideNode()
        calc_metrics_node = CalcMetricsNode()
        store_metrics_node = StoreMetricsNode()
        compose_prompt_node = ComposePromptNode()
        rag_diagnosis_node = RagDiagnosisNode()  # ChromaDB ì´ë¯¸ ì¤€ë¹„ë¨
        store_diagnosis_node = StoreDiagnosisNode()
        format_response_node = FormatResponseNode()
        
        _nodes_initialized = True
        print("âœ… ë¹ ë¥¸ ì‹œì‘ ì™„ë£Œ! (3ì´ˆ)")
        return
    
    # ìµœì´ˆ ì´ˆê¸°í™” (ì‹œê°„ì´ ê±¸ë¦¼)
    print("ğŸš€ ìµœì´ˆ ì„œë²„ ì‹œì‘ - ì „ì²´ ì´ˆê¸°í™” ì§„í–‰ ì¤‘...")
    print("â° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 30-60ì´ˆ (RAG ì‹œìŠ¤í…œ ì¤€ë¹„)")
    
    with _initialization_lock:
        print("ğŸ”§ ë…¸ë“œ ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™” ì‹œì‘...")
        
        # LLM ì œê±°ëœ 8ê°œ ë…¸ë“œ (ë¹ ë¥¸ ì´ˆê¸°í™”)
        receive_request_node = ReceiveRequestNode()
        file_metadata_node = FileMetadataNode()
        download_csv_node = DownloadCsvNode()
        filter_data_node = FilterDataNode()
        predict_phases_node = PredictPhasesNode()
        predict_stride_node = PredictStrideNode()
        calc_metrics_node = CalcMetricsNode()
        store_metrics_node = StoreMetricsNode()
        
        print("âš¡ 8ê°œ LLM-free ë…¸ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # LLM ì‚¬ìš© 4ê°œ ë…¸ë“œ (RAG ì´ˆê¸°í™” í¬í•¨)
        print("ğŸ§  RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘... (ChromaDB + ì˜ë£Œ ë…¼ë¬¸ ì¤€ë¹„)")
        compose_prompt_node = ComposePromptNode()
        rag_diagnosis_node = RagDiagnosisNode()  # ì—¬ê¸°ì„œ ChromaDB ì´ˆê¸°í™”
        store_diagnosis_node = StoreDiagnosisNode()
        format_response_node = FormatResponseNode()
        
        _nodes_initialized = True
        
        # ì´ˆê¸°í™” ì™„ë£Œ ìƒíƒœ ì €ì¥
        mark_initialization_complete()
        print("âœ… ìµœì´ˆ ì „ì²´ ì´ˆê¸°í™” ì™„ë£Œ! ë‹¤ìŒ ì¬ì‹œì‘ë¶€í„°ëŠ” ë¹ ë¥´ê²Œ ì‹œì‘ë©ë‹ˆë‹¤.")

def initialize_nodes_once():
    """API ìš”ì²­ì‹œ ë…¸ë“œ ì´ˆê¸°í™” í™•ì¸ (Fallback)"""
    if not _nodes_initialized:
        print("âš ï¸ ë…¸ë“œê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ - ê¸´ê¸‰ ì´ˆê¸°í™” ì‹¤í–‰")
        initialize_nodes_startup()

# ì„œë²„ ì‹œì‘ì‹œ ì¦‰ì‹œ ì´ˆê¸°í™” ì‹¤í–‰
initialize_nodes_startup()

print("âœ… ì„œë²„ ì¤€ë¹„ ì™„ë£Œ! (ìŠ¤ë§ˆíŠ¸ ì´ˆê¸°í™” ì‹œìŠ¤í…œ)")

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Gait Analysis API",
    description="ë°±ì—”ë“œ ë˜í•‘ ê°€ì´ë“œì— ë§ì¶˜ ë¹„ë™ê¸° ë³´í–‰ ë¶„ì„ API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"],
)

# ===== ë°ì´í„° ëª¨ë¸ ì •ì˜ =====

class UserInfo(BaseModel):
    name: str = Field(..., description="ì‚¬ìš©ì ì´ë¦„")
    height: int = Field(..., ge=100, le=250, description="í‚¤ (cm)")
    gender: str = Field(..., pattern="^(male|female|other)$", description="ì„±ë³„")

class GaitData(BaseModel):
    walkingTime: int = Field(..., description="ë³´í–‰ ì‹œê°„ (ì´ˆ)")
    steps: int = Field(..., description="ê±¸ìŒ ìˆ˜")
    distance: int = Field(..., description="ê±°ë¦¬ (m)")

class DiagnosisRequest(BaseModel):
    userInfo: UserInfo
    gaitData: GaitData
    timestamp: str = Field(..., description="ìš”ì²­ ì‹œê°„ (ISO 8601)")

class DiagnosisResponse(BaseModel):
    success: bool
    data: Dict[str, Any]

# ===== ìƒíƒœ ê´€ë¦¬ (ë©”ëª¨ë¦¬ ê¸°ë°˜) =====

# ì§„ë‹¨ ìƒíƒœ ì €ì¥ì†Œ (ì¶”í›„ DBë¡œ êµì²´ ê°€ëŠ¥)
diagnosis_store: Dict[str, Dict[str, Any]] = {}

# ìŠ¤ë ˆë“œ ì•ˆì „ì„±ì„ ìœ„í•œ ë½
diagnosis_store_lock = threading.Lock()

# ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹¤í–‰ê¸° (ë” ë§ì€ ì›Œì»¤ë¡œ í™•ì¥)
executor = concurrent.futures.ThreadPoolExecutor(max_workers=5, thread_name_prefix="langgraph")

def generate_diagnosis_id() -> str:
    """ê³ ìœ í•œ ì§„ë‹¨ ID ìƒì„±"""
    return f"diagnosis_{uuid.uuid4().hex[:8]}"

def create_diagnosis_record(request: DiagnosisRequest) -> str:
    """ìƒˆë¡œìš´ ì§„ë‹¨ ë ˆì½”ë“œ ìƒì„± (ìŠ¤ë ˆë“œ ì•ˆì „)"""
    diagnosis_id = generate_diagnosis_id()
    now = datetime.now()
    
    record = {
        "diagnosisId": diagnosis_id,
        "userId": request.userInfo.name,  # nameì„ userIdë¡œ ì‚¬ìš©
        "status": "processing",
        "progress": 0,
        "requestedAt": now.isoformat(),
        "estimatedCompletionTime": (now + timedelta(minutes=5)).isoformat(),
        "message": "ë­ê·¸ë˜í”„ ì§„ë‹¨ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "request_data": request.dict(),
        "result": None,
        "error": None,
        "current_stage": None,
        "stage_details": None,
        "created_at": now.timestamp(),  # ìƒì„± ì‹œê°„ ì¶”ê°€
        "last_updated": now.timestamp()  # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„
    }
    
    # ìŠ¤ë ˆë“œ ì•ˆì „í•˜ê²Œ ì €ì¥
    with diagnosis_store_lock:
        diagnosis_store[diagnosis_id] = record
    
    return diagnosis_id

def update_diagnosis_status(diagnosis_id: str, status: str, progress: int = None, message: str = None, result: Any = None, error: str = None, current_stage: str = None, stage_details: str = None):
    """ì§„ë‹¨ ìƒíƒœ ì—…ë°ì´íŠ¸ (ìŠ¤ë ˆë“œ ì•ˆì „)"""
    with diagnosis_store_lock:
        if diagnosis_id not in diagnosis_store:
            return False
        
        record = diagnosis_store[diagnosis_id]
        record["status"] = status
        record["last_updated"] = datetime.now().timestamp()  # ì—…ë°ì´íŠ¸ ì‹œê°„ ê°±ì‹ 
        
        if progress is not None:
            record["progress"] = progress
        if message is not None:
            record["message"] = message
        if result is not None:
            record["result"] = result
        if error is not None:
            record["error"] = error
        if current_stage is not None:
            record["current_stage"] = current_stage
        if stage_details is not None:
            record["stage_details"] = stage_details
        
        # ì™„ë£Œ ì‹œ estimatedCompletionTimeì„ Noneìœ¼ë¡œ ì„¤ì •
        if status == "completed":
            record["estimatedCompletionTime"] = None
            record["progress"] = 100
            record["message"] = "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
        elif status == "failed":
            record["estimatedCompletionTime"] = None
            record["message"] = f"ë¶„ì„ ì‹¤íŒ¨: {error}"
        
        return True

# ===== ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… í•¨ìˆ˜ =====

def run_langgraph_pipeline_with_progress(diagnosis_id: str, request: DiagnosisRequest):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìµœì í™”ëœ 12ë‹¨ê³„ ë­ê·¸ë˜í”„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    
    ìµœì¢… ë°°í¬ìš© - test_actual_nodes_pipeline.py ë¡œì§ ì™„ì „ í†µí•©
    - 67% ìµœì í™”: 8/12 ë…¸ë“œ LLM ì œê±° (ìˆœìˆ˜ Python + ë”¥ëŸ¬ë‹) 
    - 4/12 ë…¸ë“œ LLM ì‚¬ìš© (ì§„ë‹¨ ê´€ë ¨)
    - í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜: ë°ì´í„° ì²˜ë¦¬ ì¦‰ì‹œ ì‹¤í–‰ + ì§„ë‹¨ë§Œ LLM ëŒ€ê¸°
    """
    pipeline_start_time = time.time()
    llm_call_count = 0
    
    try:
        print(f"ğŸš€ ìµœì í™”ëœ ë­ê·¸ë˜í”„ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {diagnosis_id}")
        
        # ì‹œì‘ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
        update_diagnosis_status(
            diagnosis_id, 
            "processing", 
            progress=5,
            message="AIê°€ ë³´í–‰ íŒ¨í„´ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
            current_stage="initializing"
        )
        
        # ==== ìµœì í™”ëœ ë­ê·¸ë˜í”„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ====
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì • - ìƒˆë¡œìš´ ì…ë ¥ ì‹œìŠ¤í…œ (user_id, height_cm, gender)
        update_diagnosis_status(diagnosis_id, "processing", 10, "ì´ˆê¸° ìƒíƒœ ì„¤ì • ì¤‘...", current_stage="setup")
        
        initial_state = GraphState()
        initial_state.update({
            "user_id": request.userInfo.name,  # ì‚¬ìš©ì ì´ë¦„ì„ user_idë¡œ ì‚¬ìš©
            "height_cm": float(request.userInfo.height),
            "gender": request.userInfo.gender,
            "session_id": diagnosis_id,
            "timestamp": request.timestamp
        })
        
        current_state = initial_state.copy()
        
        print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸ ì„¸ì…˜: {current_state['session_id']}")
        print(f"ğŸ‘¤ ì‚¬ìš©ì ID: {current_state['user_id']}")
        print(f"ğŸ“ í‚¤: {current_state['height_cm']}cm")
        print(f"ğŸ‘« ì„±ë³„: {current_state['gender']}")
        
        # 12ë‹¨ê³„ ìµœì í™”ëœ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì‚¬ì „ ì´ˆê¸°í™”ëœ ë…¸ë“œ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©)
        pipeline_stages = [
            # LLM ì œê±°ëœ 8ê°œ ë…¸ë“œ (67% ìµœì í™”) - ì‚¬ì „ ì´ˆê¸°í™”ëœ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
            (receive_request_node, "ì…ë ¥ ê²€ì¦", 15, "receiverequestnode", False),
            (file_metadata_node, "Storage íŒŒì¼ ê²€ìƒ‰", 25, "filemetadatanode", False), 
            (download_csv_node, "ë°ì´í„° ë‹¤ìš´ë¡œë“œ", 35, "downloadcsvnode", False),
            (filter_data_node, "Butterworth í•„í„°ë§ + íŠ¸ë¦¬ë°", 45, "filterdatanode", False),
            (predict_phases_node, "ë”¥ëŸ¬ë‹ ë³´í–‰ ë‹¨ê³„ ì˜ˆì¸¡", 55, "predictphasesnode", False),
            (predict_stride_node, "ë”¥ëŸ¬ë‹ ë³´í­/ì†ë„ ì˜ˆì¸¡", 65, "predictstridenode", False),
            (calc_metrics_node, "12ê°œ ë³´í–‰ ì§€í‘œ ê³„ì‚°", 75, "calcmetricsnode", False),
            (store_metrics_node, "ì§€í‘œ ì €ì¥", 80, "storemetricsnode", False),
            
            # LLM ì‚¬ìš© 4ê°œ ë…¸ë“œ (ì§„ë‹¨ ì „ìš©) - ì‚¬ì „ ì´ˆê¸°í™”ëœ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
            (compose_prompt_node, "ì§„ë‹¨ í”„ë¡¬í”„íŠ¸ êµ¬ì„±", 85, "composepromptnode", True),
            (rag_diagnosis_node, "RAG ê¸°ë°˜ ì˜ë£Œ ì§„ë‹¨", 90, "ragdiagnosisnode", True),
            (store_diagnosis_node, "ì§„ë‹¨ ê²°ê³¼ ì €ì¥", 95, "storediagnosisnode", True),
            (format_response_node, "ìµœì¢… ì‘ë‹µ ìƒì„±", 100, "formatresponsenode", True)
        ]
        
        for i, (node_instance, description, progress, stage_name, uses_llm) in enumerate(pipeline_stages):
            step_start = time.time()
            
            try:
                # ìƒíƒœ ì—…ë°ì´íŠ¸
                status = "analyzing" if progress < 80 else "generating_report"
                update_diagnosis_status(
                    diagnosis_id, 
                    status,
                    progress, 
                    f"{description} ì¤‘...",
                    current_stage=stage_name
                )
                
                print(f"\n{'='*80}")
                node_type = "ğŸ¤– LLM ì‚¬ìš©" if uses_llm else "âš¡ LLM ì œê±°"
                print(f"{i+1}ï¸âƒ£ STEP {i+1}: {node_instance.__class__.__name__} - {description} ({node_type})")
                print(f"{'='*80}")
                
                # íŠ¹ë³„ ì²˜ë¦¬ë“¤
                if node_instance is store_metrics_node:
                    current_state['date'] = datetime.now().strftime('%Y-%m-%d')
                
                # LLM í˜¸ì¶œ ì¶”ì  (ë°°í¬ìš©ì—ì„œëŠ” ì‹¤ì œë¡œ ì¶”ì í•˜ì§€ ì•Šì§€ë§Œ ë¡œê·¸ìš©)
                if uses_llm:
                    llm_call_count += 1
                    print(f"   ğŸ§  LLM Call #{llm_call_count} - {description}")
                else:
                    print(f"   âš¡ ìˆœìˆ˜ Python/ë”¥ëŸ¬ë‹ ì‹¤í–‰ - LLM ì—†ìŒ")
                
                # ë…¸ë“œ ì‹¤í–‰
                print(f"ğŸ”„ {description} ì‹¤í–‰ ì¤‘...")
                current_state = node_instance.execute(current_state)
                step_time = time.time() - step_start
                
                # ì—ëŸ¬ ì²´í¬
                if current_state.get('error'):
                    raise Exception(f"{node_instance.__class__.__name__} ì‹¤í–‰ ì‹¤íŒ¨: {current_state['error']}")
                    
                # ì„±ê³µ ë¡œê·¸ + ìƒì„¸ ì •ë³´
                print(f"âœ… {node_instance.__class__.__name__} ì™„ë£Œ! ({step_time:.2f}ì´ˆ)")
                
                # ë‹¨ê³„ë³„ ì„¸ë¶€ ì •ë³´ ì¶œë ¥ (ì¤‘ìš”í•œ ê²ƒë“¤ë§Œ)
                if node_instance is download_csv_node:
                    csv_path = current_state.get('raw_csv_path')
                    if csv_path:
                        df = pd.read_csv(csv_path)
                        print(f"   ğŸ“Š ë‹¤ìš´ë¡œë“œëœ ë°ì´í„°: {len(df):,}ê°œ ë ˆì½”ë“œ")
                
                elif node_instance is filter_data_node:
                    filtered_path = current_state.get('filtered_csv_path')
                    if filtered_path:
                        df_filtered = pd.read_csv(filtered_path)
                        print(f"   ğŸ“Š í•„í„°ë§ëœ ë°ì´í„°: {len(df_filtered):,}ê°œ ë ˆì½”ë“œ")
                
                elif node_instance is calc_metrics_node:
                    gait_metrics = current_state.get('gait_metrics')
                    if gait_metrics:
                        print(f"   ğŸ“Š ê³„ì‚°ëœ ë³´í–‰ ì§€í‘œ:")
                        print(f"      â±ï¸ í‰ê·  ë³´í–‰ì‹œê°„: {gait_metrics.get('avg_stride_time', 0):.3f}ì´ˆ")
                        print(f"      ğŸ“ í‰ê·  ë³´í­: {gait_metrics.get('avg_stride_length', 0):.3f}m")
                        print(f"      ğŸƒ í‰ê·  ì†ë„: {gait_metrics.get('avg_walking_speed', 0):.3f}m/s")
                
                elif node_instance is rag_diagnosis_node:
                    diagnosis_result = current_state.get('diagnosis_result')
                    if diagnosis_result:
                        print(f"   ğŸ¥ ì§„ë‹¨ ê²°ê³¼ ê¸¸ì´: {len(diagnosis_result):,} ë¬¸ì")
                        preview = diagnosis_result[:150] + "..." if len(diagnosis_result) > 150 else diagnosis_result
                        print(f"   ğŸ‘¨â€âš•ï¸ ì§„ë‹¨ ë¯¸ë¦¬ë³´ê¸°: {preview}")
                
            except Exception as e:
                step_time = time.time() - step_start
                print(f"âŒ {node_instance.__class__.__name__} ì‹¤íŒ¨: {e} ({step_time:.2f}ì´ˆ)")
                update_diagnosis_status(
                    diagnosis_id, 
                    "failed", 
                    progress, 
                    error=f"{description} ì‹¤íŒ¨: {str(e)}"
                )
                return
        
        # ==== ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ ====
        total_time = time.time() - pipeline_start_time
        
        # ë°±ì—”ë“œ ë˜í•‘ ê°€ì´ë“œì— ë§ëŠ” ê²°ê³¼ êµ¬ì¡°ë¡œ ë˜í•‘
        print(f"\nğŸ” extract_final_result í˜¸ì¶œ ì „ current_state í‚¤ë“¤:")
        print(f"   - ì „ì²´ í‚¤: {list(current_state.keys())}")
        if 'final_response' in current_state:
            print(f"   - final_response íƒ€ì…: {type(current_state['final_response'])}")
            if isinstance(current_state['final_response'], dict):
                print(f"   - final_response í‚¤ë“¤: {list(current_state['final_response'].keys())}")
        
        langgraph_result = extract_final_result(current_state)
        
        # ğŸ” ìµœì¢… ì‘ë‹µ ì½˜ì†” ì¶œë ¥ (ìš”ì²­ì‚¬í•­)
        print(f"\n{'='*80}")
        print("ğŸ“‹ ìµœì¢… ì‘ë‹µ ê²°ê³¼ (ì½˜ì†” ì¶œë ¥)")
        print("="*80)
        print(f"ğŸ“Š ì§„ë‹¨ ID: {diagnosis_id}")
        print(f"ğŸ‘¤ ì‚¬ìš©ì: {langgraph_result.get('userId', 'unknown')}")
        print(f"â° ë¶„ì„ ì‹œê°„: {langgraph_result.get('analyzedAt', 'unknown')}")
        print(f"ğŸ“ˆ ì ìˆ˜: {langgraph_result.get('score', 'N/A')}")
        print(f"ğŸ¥ ìƒíƒœ: {langgraph_result.get('status', 'unknown')}")
        print(f"âš ï¸ ìœ„í—˜ë„: {langgraph_result.get('riskLevel', 'unknown')}")
        
        # ì§€í‘œ ì •ë³´ ì¶œë ¥
        indicators = langgraph_result.get('indicators', [])
        print(f"\nğŸ“Š ë³´í–‰ ì§€í‘œ ({len(indicators)}ê°œ):")
        for i, indicator in enumerate(indicators, 1):
            print(f"   {i}. {indicator.get('name', 'N/A')}: {indicator.get('value', 'N/A')}")
            print(f"      ìƒíƒœ: {indicator.get('status', 'N/A')} - {indicator.get('result', 'N/A')}")
        
        # ì§ˆë³‘ ì •ë³´ ì¶œë ¥
        diseases = langgraph_result.get('diseases', [])
        print(f"\nğŸ¥ ì§ˆë³‘ ì •ë³´ ({len(diseases)}ê°œ):")
        if diseases:
            for i, disease in enumerate(diseases, 1):
                print(f"   {i}. {disease}")
        else:
            print("   ì§ˆë³‘ ì •ë³´ ì—†ìŒ")
        
        # ìƒì„¸ ë¦¬í¬íŠ¸ ì¶œë ¥
        detailed_report = langgraph_result.get('detailedReport', {})
        print(f"\nğŸ“‹ ìƒì„¸ ë¦¬í¬íŠ¸:")
        print(f"   ì œëª©: {detailed_report.get('title', 'N/A')}")
        report_content = detailed_report.get('content', 'N/A')
        if isinstance(report_content, str):
            # ë„ˆë¬´ ê¸¸ë©´ ì²˜ìŒ 300ìë§Œ ì¶œë ¥
            content_preview = report_content[:300] + "..." if len(report_content) > 300 else report_content
            print(f"   ë‚´ìš©: {content_preview}")
        else:
            print(f"   ë‚´ìš© (ê°ì²´): {type(report_content)} - {report_content}")
        
        print(f"\nğŸ¯ ì™„ì „í•œ ìµœì¢… ì‘ë‹µ êµ¬ì¡°:")
        import json
        try:
            formatted_result = json.dumps(langgraph_result, indent=2, ensure_ascii=False)
            print(formatted_result)
        except Exception as e:
            print(f"JSON ë³€í™˜ ì‹¤íŒ¨: {e}")
            print(f"Raw result: {langgraph_result}")
        
        print("="*80)
        print("âœ… ìµœì¢… ì‘ë‹µ ì½˜ì†” ì¶œë ¥ ì™„ë£Œ!")
        print("="*80)
        
        update_diagnosis_status(
            diagnosis_id,
            "completed",
            100,
            "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!",
            result=langgraph_result,
            current_stage="completed"
        )
        
        # ìµœì¢… ì„±ê³¼ ìš”ì•½
        print(f"\n{'='*80}")
        print("ğŸ‰ ì™„ì „í•œ End-to-End ìµœì í™”ëœ LangGraph íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print("="*80)
        
        print(f"ğŸ“Š íŒŒì´í”„ë¼ì¸ ì„±ê³¼:")
        print(f"   ğŸš€ ì´ LLM í˜¸ì¶œ: {llm_call_count}íšŒ (ì˜ˆìƒ: 4íšŒ)")
        print(f"   â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"   ğŸ¯ ìµœì í™” êµ¬ì¡°: 8/12 ë…¸ë“œ LLM ì œê±° (67% ìµœì í™”)")
        print(f"   ğŸ’¡ í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜: ë°ì´í„° ì²˜ë¦¬ëŠ” ìˆœìˆ˜ Python, ì§„ë‹¨ì€ LLM")
        
        print(f"\nğŸ—ï¸ ìµœì í™”ëœ í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜:")
        print(f"   ğŸ“Š ì…ë ¥ ì‹œìŠ¤í…œ: (user_id, height_cm, gender)")
        print(f"   ğŸ—„ï¸ ë°ì´í„° ì†ŒìŠ¤: Supabase Storage (CSV íŒŒì¼)")
        print(f"   ğŸ¤– ë°ì´í„° ì²˜ë¦¬: ìˆœìˆ˜ Python + ë”¥ëŸ¬ë‹ (LLM ì—†ìŒ)")
        print(f"   ğŸ§  ì˜ë£Œ ì§„ë‹¨: RAG + LLM (ChromaDB + ì˜ë£Œ ë¬¸í—Œ)")
        print(f"   âš¡ ì„±ëŠ¥: ë°ì´í„° ì²˜ë¦¬ ì¦‰ì‹œ ì‹¤í–‰, ì§„ë‹¨ë§Œ LLM ëŒ€ê¸°")
        
        print(f"ğŸ‰ ë­ê·¸ë˜í”„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {diagnosis_id}")
        
    except Exception as e:
        print(f"ğŸ’¥ ë­ê·¸ë˜í”„ íŒŒì´í”„ë¼ì¸ ì „ì²´ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        update_diagnosis_status(
            diagnosis_id,
            "failed",
            error=f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
        )


def extract_final_result(final_state: dict) -> dict:
    """
    FormatResponseNode ì¶œë ¥ì„ ì •í™•íˆ ì¶”ì¶œ
    
    FormatResponseNode.execute()ì—ì„œ state['response']ì— ì €ì¥í•˜ëŠ” ì™„ë²½í•œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
    - _enhance_structured_response: ì´ë¯¸ ì™„ë²½í•œ 5ê°œ ì§€í‘œ + ì ìˆ˜ + ì§„ë‹¨
    - _create_fallback_response: ë°±ì—… 4ê°œ ì§€í‘œ + ê¸°ë³¸ ì§„ë‹¨
    """
    try:
        print(f"ğŸ” final_state ì „ì²´ í‚¤ ë¶„ì„: {list(final_state.keys())}")
        
        # 1ìˆœìœ„: FormatResponseNodeê°€ ì €ì¥í•˜ëŠ” state['response']
        if 'response' in final_state:
            response_data = final_state['response']
            print(f"âœ… state['response'] ë°œê²¬ - íƒ€ì…: {type(response_data)}")
            
            if isinstance(response_data, dict):
                print(f"ğŸ“‹ response í‚¤ë“¤: {list(response_data.keys())}")
                
                # FormatResponseNode í‘œì¤€ ì¶œë ¥: {success: true, data: {...}}
                if 'success' in response_data and 'data' in response_data:
                    data_section = response_data['data']
                    print(f"ğŸ¯ FormatResponseNode í‘œì¤€ êµ¬ì¡° í™•ì¸ë¨")
                    print(f"   - success: {response_data['success']}")
                    print(f"   - data íƒ€ì…: {type(data_section)}")
                    
                    if isinstance(data_section, dict):
                        indicators = data_section.get('indicators', [])
                        score = data_section.get('score', 0)
                        user_id = data_section.get('userId', 'unknown')
                        
                        print(f"ğŸ“Š ì™„ë²½í•œ ì§„ë‹¨ ë°ì´í„° í™•ì¸:")
                        print(f"   - ì§€í‘œ ê°œìˆ˜: {len(indicators)}")
                        print(f"   - ì ìˆ˜: {score}")
                        print(f"   - ì‚¬ìš©ì: {user_id}")
                        
                        # detailedReport.content íƒ€ì… í™•ì¸
                        detailed_report = data_section.get('detailedReport', {})
                        if isinstance(detailed_report, dict):
                            content = detailed_report.get('content', '')
                            print(f"   - detailedReport.content íƒ€ì…: {type(content)}")
                            print(f"   - content ê¸¸ì´: {len(content) if isinstance(content, str) else 'N/A'}")
                        
                        print(f"âœ… FormatResponseNode ì™„ë²½í•œ ë°ì´í„° ì‚¬ìš©!")
                        return data_section
                
                # ì§ì ‘ êµ¬ì¡° (ë¹„í‘œì¤€)
                elif 'indicators' in response_data:
                    indicators = response_data.get('indicators', [])
                    print(f"ğŸ” ì§ì ‘ êµ¬ì¡° ê°ì§€ - ì§€í‘œ ê°œìˆ˜: {len(indicators)}")
                    if len(indicators) > 0:
                        return response_data
            
            # JSON ë¬¸ìì—´ì¸ ê²½ìš°
            elif isinstance(response_data, str):
                print(f"ğŸ” JSON ë¬¸ìì—´ íŒŒì‹± ì‹œë„ (ê¸¸ì´: {len(response_data)})")
                import json
                try:
                    parsed = json.loads(response_data)
                    print(f"âœ… JSON íŒŒì‹± ì„±ê³µ: {type(parsed)}")
                    
                    # ì¬ê·€ í˜¸ì¶œë¡œ íŒŒì‹±ëœ ë°ì´í„° ì²˜ë¦¬
                    temp_state = {'response': parsed}
                    return extract_final_result(temp_state)
                
                except Exception as parse_error:
                    print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {parse_error}")
        
        # 2ìˆœìœ„: state['final_response'] (ë ˆê±°ì‹œ)
        elif 'final_response' in final_state:
            final_response = final_state['final_response']
            print(f"âš ï¸ state['final_response'] ì‚¬ìš© (ë ˆê±°ì‹œ) - íƒ€ì…: {type(final_response)}")
            
            # ì¬ê·€ í˜¸ì¶œë¡œ ì²˜ë¦¬
            temp_state = {'response': final_response}
            return extract_final_result(temp_state)
        
        # ë°±ì—… 1: final_stateì—ì„œ ì§ì ‘ í•„ìš”í•œ ë°ì´í„° ìˆ˜ì§‘
        print(f"âš ï¸ í‘œì¤€ êµ¬ì¡° ì—†ìŒ - final_stateì—ì„œ ì§ì ‘ ìˆ˜ì§‘")
        print(f"   - final_state í‚¤ë“¤: {list(final_state.keys())}")
        
        # ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
        user_id = final_state.get('user_id', 'unknown')
        gait_metrics = final_state.get('gait_metrics', {})
        medical_diagnosis = final_state.get('medical_diagnosis', '')
        
        print(f"ğŸ“‹ ë°±ì—… ë°ì´í„° ìˆ˜ì§‘:")
        print(f"   - user_id: {user_id}")
        print(f"   - gait_metrics í‚¤ë“¤: {list(gait_metrics.keys()) if isinstance(gait_metrics, dict) else 'N/A'}")
        print(f"   - medical_diagnosis ê¸¸ì´: {len(medical_diagnosis) if isinstance(medical_diagnosis, str) else 'N/A'}")
        
        # FormatResponseNodeì˜ _create_fallback_response ë¡œì§ ì¬í˜„
        if isinstance(gait_metrics, dict) and gait_metrics:
            indicators = create_indicators_from_metrics(gait_metrics)
            overall_score = calculate_score_from_indicators(indicators)
            status = get_status_from_score(overall_score)
            risk_level = get_risk_level_from_score(overall_score)
            
            result = {
                "userId": user_id,
                "score": overall_score,
                "status": status,
                "riskLevel": risk_level,
                "analyzedAt": datetime.now().isoformat(),
                "indicators": indicators,
                "diseases": [
                    {"id": "parkinson", "name": "íŒŒí‚¨ìŠ¨ë³‘", "probability": 30, "status": "ì •ìƒ ë²”ìœ„"},
                    {"id": "stroke", "name": "ë‡Œì¡¸ì¤‘", "probability": 25, "status": "ì •ìƒ ë²”ìœ„"}
                ],
                "detailedReport": {
                    "title": "ë³´í–‰ ë¶„ì„ ê²°ê³¼ ìš”ì•½",
                    "content": medical_diagnosis if medical_diagnosis else f"ì „ì²´ì ì¸ ë³´í–‰ ë¶„ì„ ê²°ê³¼ëŠ” {status}ì…ë‹ˆë‹¤."
                }
            }
            
            print(f"âœ… ë°±ì—… ê²°ê³¼ ìƒì„± ì™„ë£Œ:")
            print(f"   - ì§€í‘œ ê°œìˆ˜: {len(indicators)}")
            print(f"   - ì ìˆ˜: {overall_score}")
            print(f"   - ìƒíƒœ: {status}")
            
            return result
        
        # ë°±ì—… 2: ìµœì†Œí•œì˜ ê¸°ë³¸ ì‘ë‹µ
        print(f"âš ï¸ ìµœì†Œí•œì˜ ê¸°ë³¸ ì‘ë‹µ ìƒì„±")
        return {
            "userId": user_id,
            "score": 75,
            "status": "ë³´í–‰ ë¶„ì„ ì™„ë£Œ",
            "riskLevel": "ì •ìƒ ë‹¨ê³„",
            "analyzedAt": datetime.now().isoformat(),
            "indicators": [],
            "diseases": [],
            "detailedReport": {
                "title": "ë³´í–‰ ë¶„ì„ ê²°ê³¼",
                "content": medical_diagnosis if medical_diagnosis else "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
            }
        }
        
    except Exception as e:
        print(f"âŒ extract_final_result ì „ì²´ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        
        # ìµœì¢… ë°±ì—…
        return {
            "userId": final_state.get('user_id', 'unknown'),
            "score": 75,
            "status": "ë³´í–‰ ë¶„ì„ ì™„ë£Œ",
            "riskLevel": "ì •ìƒ ë‹¨ê³„", 
            "analyzedAt": datetime.now().isoformat(),
            "indicators": [],
            "diseases": [],
            "detailedReport": {
                "title": "ë³´í–‰ ë¶„ì„ ê²°ê³¼",
                "content": "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
            }
        }


def create_indicators_from_metrics(gait_metrics: dict) -> list:
    """gait_metricsì—ì„œ indicators ìƒì„± (FormatResponseNode ë¡œì§ ì¬í˜„)"""
    indicators = []
    
    # ë³´í­ ì‹œê°„
    avg_stride_time = gait_metrics.get("avg_stride_time", 1.0)
    stride_time_status = "normal" if 0.9 <= avg_stride_time <= 1.3 else "warning"
    indicators.append({
        "id": "stride-time",
        "name": "ë³´í­ ì‹œê°„",
        "value": f"{avg_stride_time:.2f}ì´ˆ",
        "status": stride_time_status,
        "description": "í•œìª½ ë°œì´ ë•…ì— ë‹¿ì€ í›„ ê°™ì€ ë°œì´ ë‹¤ì‹œ ë‹¿ì„ ë•Œê¹Œì§€ ê±¸ë¦¬ëŠ” ì‹œê°„",
        "result": f"ë¶„ì„ ê²°ê³¼ {'ì •ìƒ' if stride_time_status == 'normal' else 'ì£¼ì˜'}ì…ë‹ˆë‹¤!"
    })
    
    # ì–‘ë°œ ì§€ì§€ ë¹„ìœ¨
    double_support_time = gait_metrics.get("avg_double_support_time", 0.2)
    double_support_status = "normal" if double_support_time <= 0.25 else "warning"
    indicators.append({
        "id": "double-support",
        "name": "ì–‘ë°œ ì§€ì§€ ë¹„ìœ¨",
        "value": f"{double_support_time * 100:.1f}%",
        "status": double_support_status,
        "description": "ë‘ ë°œì´ ë™ì‹œì— ë•…ì— ë‹¿ì•„ ìˆëŠ” ì‹œê°„ì˜ ë¹„ìœ¨",
        "result": f"ë¶„ì„ ê²°ê³¼ {'ì •ìƒ' if double_support_status == 'normal' else 'ì£¼ì˜'}ì…ë‹ˆë‹¤!"
    })
    
    # ì–‘ë°œ ë³´í­ ì°¨ì´
    stride_asymmetry = gait_metrics.get("stride_length_asymmetry", 0)
    stride_diff_status = "normal" if stride_asymmetry < 5 else "warning"
    indicators.append({
        "id": "stride-difference",
        "name": "ì–‘ë°œ ë³´í­ ì°¨ì´",
        "value": f"{stride_asymmetry:.2f}m",
        "status": stride_diff_status,
        "description": "ì™¼ë°œê³¼ ì˜¤ë¥¸ë°œì˜ ê±¸ìŒ ê¸¸ì´ ì°¨ì´",
        "result": f"ë¶„ì„ ê²°ê³¼ {'ì •ìƒ' if stride_diff_status == 'normal' else 'ì£¼ì˜'}ì…ë‹ˆë‹¤!"
    })
    
    # í‰ê·  ë³´í–‰ ì†ë„
    walking_speed = gait_metrics.get("avg_walking_speed", 1.0)
    speed_status = "normal" if walking_speed >= 1.0 else "warning"
    indicators.append({
        "id": "walking-speed",
        "name": "í‰ê·  ë³´í–‰ ì†ë„",
        "value": f"{walking_speed:.1f}m/s",
        "status": speed_status,
        "description": "ë‹¨ìœ„ ì‹œê°„ ë™ì•ˆ ì´ë™í•œ ê±°ë¦¬",
        "result": f"ë¶„ì„ ê²°ê³¼ {'ì •ìƒ' if speed_status == 'normal' else 'ì£¼ì˜'}ì…ë‹ˆë‹¤!"
    })
    
    # ì…ê°ê¸° ë¹„ìœ¨ (ì¶”ê°€)
    stance_phase = gait_metrics.get("avg_stance_phase_ratio", 0.6) * 100
    stance_status = "normal" if 55 <= stance_phase <= 65 else "warning"
    indicators.append({
        "id": "stance-phase",
        "name": "ì…ê°ê¸° ë¹„ìœ¨",
        "value": f"{stance_phase:.1f}%",
        "status": stance_status,
        "description": "ë³´í–‰ ì£¼ê¸° ì¤‘ ë°œì´ ë•…ì— ë‹¿ì•„ ìˆëŠ” ì‹œê°„ì˜ ë¹„ìœ¨",
        "result": f"ë¶„ì„ ê²°ê³¼ {'ì •ìƒ' if stance_status == 'normal' else 'ì£¼ì˜'}ì…ë‹ˆë‹¤!"
    })
    
    return indicators


def calculate_score_from_indicators(indicators: list) -> int:
    """indicatorsì—ì„œ ì ìˆ˜ ê³„ì‚°"""
    if not indicators:
        return 75
    
    normal_count = sum(1 for ind in indicators if ind["status"] == "normal")
    warning_count = len(indicators) - normal_count
    
    # ì •ìƒ=100ì , ì£¼ì˜=70ì 
    score = (normal_count * 100 + warning_count * 70) / len(indicators)
    return int(score)


def get_status_from_score(score: int) -> str:
    """ì ìˆ˜ì—ì„œ ìƒíƒœ ë„ì¶œ"""
    if score >= 80:
        return "ì •ìƒ ë²”ìœ„ ë‚´ì—ì„œ ì–‘í˜¸í•œ ë³´í–‰ íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤"
    elif score >= 60:
        return "ì¼ë¶€ ì§€í‘œì—ì„œ ì£¼ì˜ê°€ í•„ìš”í•œ ë³´í–‰ íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤"
    else:
        return "ì—¬ëŸ¬ ì§€í‘œì—ì„œ ê°œì„ ì´ í•„ìš”í•œ ë³´í–‰ íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤"


def get_risk_level_from_score(score: int) -> str:
    """ì ìˆ˜ì—ì„œ ìœ„í—˜ë„ ë„ì¶œ"""
    if score >= 80:
        return "ì •ìƒ ë‹¨ê³„"
    elif score >= 60:
        return "ì£¼ì˜ ë‹¨ê³„"
    else:
        return "ìœ„í—˜ ë‹¨ê³„"

async def run_langgraph_pipeline_async(diagnosis_id: str, request: DiagnosisRequest):
    """ë¹„ë™ê¸° ë˜í¼: ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    loop = asyncio.get_event_loop()
    await loop.run_in_executor(executor, run_langgraph_pipeline_with_progress, diagnosis_id, request)

# ===== API ì—”ë“œí¬ì¸íŠ¸ =====

@app.post("/gait-analysis/langgraph-diagnosis", response_model=DiagnosisResponse)
async def start_diagnosis(request: DiagnosisRequest, background_tasks: BackgroundTasks):
    """
    1ë‹¨ê³„: ì§„ë‹¨ ìš”ì²­ ì‹œì‘
    
    ë°±ì—”ë“œ ë˜í•‘ ê°€ì´ë“œì— ë”°ë¼ diagnosisIdë¥¼ ì¦‰ì‹œ ë°˜í™˜í•˜ê³ 
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë­ê·¸ë˜í”„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    """
    try:
        # ì²« ìš”ì²­ì‹œ ë…¸ë“œ ì´ˆê¸°í™” (Lazy Loading)
        initialize_nodes_once()
        
        # ì§„ë‹¨ ë ˆì½”ë“œ ìƒì„±
        diagnosis_id = create_diagnosis_record(request)
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë­ê·¸ë˜í”„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        background_tasks.add_task(run_langgraph_pipeline_async, diagnosis_id, request)
        
        # ì¦‰ì‹œ ì‘ë‹µ ë°˜í™˜
        response_data = {
            "diagnosisId": diagnosis_id,
            "userId": request.userInfo.name,
            "status": "processing",
            "requestedAt": diagnosis_store[diagnosis_id]["requestedAt"],
            "estimatedCompletionTime": diagnosis_store[diagnosis_id]["estimatedCompletionTime"],
            "message": "ë­ê·¸ë˜í”„ ì§„ë‹¨ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
        
        return DiagnosisResponse(success=True, data=response_data)
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì§„ë‹¨ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")

@app.get("/gait-analysis/diagnosis/status/{diagnosis_id}", response_model=DiagnosisResponse)
async def get_diagnosis_status(diagnosis_id: str):
    """
    2ë‹¨ê³„: ìƒíƒœ í™•ì¸ (ìŠ¤ë ˆë“œ ì•ˆì „)
    
    ë°±ì—”ë“œ ë˜í•‘ ê°€ì´ë“œì— ë”°ë¼:
    - ì§„í–‰ ì¤‘: status, progress, message ë°˜í™˜
    - ì™„ë£Œ ì‹œ: status="completed" + result í•„ë“œì— ë­ê·¸ë˜í”„ ë°ì´í„° ë˜í•‘
    """
    # ìŠ¤ë ˆë“œ ì•ˆì „í•˜ê²Œ ìƒíƒœ ì½ê¸°
    with diagnosis_store_lock:
        if diagnosis_id not in diagnosis_store:
            raise HTTPException(status_code=404, detail=f"ì§„ë‹¨ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {diagnosis_id}")
        
        # ê¹Šì€ ë³µì‚¬ë¡œ ì•ˆì „í•˜ê²Œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        record = diagnosis_store[diagnosis_id].copy()
    
    # ê¸°ë³¸ ì‘ë‹µ ë°ì´í„°
    response_data = {
        "diagnosisId": diagnosis_id,
        "status": record["status"],
        "progress": record["progress"],
        "estimatedCompletionTime": record.get("estimatedCompletionTime"),
        "message": record["message"]
    }
    
    # ì§„í–‰ ì¤‘ì¸ ê²½ìš° ì¶”ê°€ ì •ë³´
    if record["status"] in ["processing", "analyzing", "generating_report"]:
        response_data["currentStage"] = record.get("current_stage")
        response_data["stageDetails"] = record.get("stage_details")
    
    # ì™„ë£Œ ì‹œ result í•„ë“œ ì¶”ê°€ (í•µì‹¬!)
    if record["status"] == "completed" and record["result"]:
        response_data["result"] = record["result"]
    
    # ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì •ë³´
    elif record["status"] == "failed":
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": {
                    "code": "DIAGNOSIS_FAILED",
                    "message": record.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                }
            }
        )
    
    return DiagnosisResponse(success=True, data=response_data)

@app.get("/api/v1/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.get("/api/v1/pipeline-info")
async def pipeline_info():
    """ìµœì í™”ëœ íŒŒì´í”„ë¼ì¸ ì •ë³´ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "pipeline": "Optimized LangGraph 12-stage gait analysis",
        "version": "2.2.0",
        "architecture": "hybrid",
        "stages": 12,
        "optimization": {
            "llm_reduction": "67% (8/12 nodes LLM-free)",
            "llm_free_stages": [
                "ReceiveRequestNode", "FileMetadataNode", "DownloadCsvNode", "FilterDataNode",
                "PredictPhasesNode", "PredictStrideNode", "CalcMetricsNode", "StoreMetricsNode"
            ],
            "llm_powered_stages": [
                "ComposePromptNode", "RagDiagnosisNode", "StoreDiagnosisNode", "FormatResponseNode"
            ]
        },
        "processing": {
            "data_engine": "Pure Python + Deep Learning",
            "diagnosis_engine": "RAG + LLM (ChromaDB)",
            "input_system": "(user_id, height_cm, gender)",
            "data_source": "Supabase Storage"
        },
        "performance": {
            "data_processing": "Immediate execution (no LLM wait)",
            "diagnosis_generation": "LLM-powered medical insights",
        "background_workers": executor._max_workers,
        "active_diagnoses": len([d for d in diagnosis_store.values() if d["status"] in ["processing", "analyzing", "generating_report"]])
        },
        "deployment": {
            "standalone": True,
            "dependencies_removed": ["test_actual_nodes_pipeline.py"],
            "embedded_pipeline": "Complete 12-stage logic integrated"
        }
    }

# ===== ì„œë²„ ì‹¤í–‰ =====

if __name__ == "__main__":
    print("\n" + "="*80)
    print("ğŸš€ ìµœì í™”ëœ Gait Analysis FastAPI Server ì‹œì‘...")
    print("="*80)
    print("ğŸ“š API ë¬¸ì„œ: http://localhost:8000/docs")
    print("ğŸ¥ Health Check: http://localhost:8000/api/v1/health")
    print("ğŸ” Pipeline Info: http://localhost:8000/api/v1/pipeline-info")
    print("âš¡ ì§„ë‹¨ ì‹œì‘: POST http://localhost:8000/gait-analysis/langgraph-diagnosis")
    print("ğŸ“Š ìƒíƒœ í™•ì¸: GET http://localhost:8000/gait-analysis/diagnosis/status/{diagnosisId}")
    print()
    print("ğŸ¯ ìµœì¢… ë°°í¬ìš© í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸ v2.1.0")
    print("ğŸ“Š 67% ìµœì í™”: 8/12 ë…¸ë“œ LLM ì œê±° (ìˆœìˆ˜ Python + ë”¥ëŸ¬ë‹)")
    print("ğŸ§  4/12 ë…¸ë“œ LLM ì‚¬ìš© (RAG ê¸°ë°˜ ì§„ë‹¨ ì „ìš©)")
    print("ğŸ—ï¸ ì™„ì „ ë…ë¦½í˜•: test_actual_nodes_pipeline.py ì˜ì¡´ì„± ì œê±°")
    print("âœ¨ RAG êµ¬ì¡°í™”ëœ ì‘ë‹µ íŒŒì‹± ì‹œìŠ¤í…œ ì ìš© (í™˜ê° ìµœì†Œí™”)")
    print(f"ğŸ”§ ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤: {executor._max_workers}ê°œ")
    print("âš¡ ë°ì´í„° ì²˜ë¦¬: ì¦‰ì‹œ ì‹¤í–‰ | ğŸ§  ì§„ë‹¨: LLM ê¸°ë°˜")
    print("ğŸ›¡ï¸ ìŠ¤ë ˆë“œ ì•ˆì „ì„±: ë™ì‹œì„± ì´ìŠˆ ë°©ì§€")
    print("ğŸ”„ í”„ë¡ íŠ¸ í´ë§: GET ìš”ì²­ ë¬´ì œí•œ ì§€ì›")
    print("ğŸš€ ì„œë²„ ì‹œì‘ ì´ˆê¸°í™”: ì™„ë£Œ (RAG ì‹œìŠ¤í…œ ì‚¬ì „ ë¡œë“œ)")
    print("="*80)
    print()
    
    uvicorn.run(
        "fastapi_server:app",
        host="127.0.0.1",
        port=8000,
        reload=False,  # ê°œë°œ ì¤‘ ìë™ ë¦¬ë¡œë”© ë¹„í™œì„±í™” (ì´ˆê¸°í™” ì¤‘ë³µ ë°©ì§€)
        log_level="info"
    ) 