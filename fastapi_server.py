#!/usr/bin/env python3
"""
Gait Analysis FastAPI Server
ë°±ì—”ë“œ ë˜í•‘ ê°€ì´ë“œì— ë§ì¶˜ ë¹„ë™ê¸° ì§„ë‹¨ API ì„œë²„

Requirements:
- POST /gait-analysis/langgraph-diagnosis: ì§„ë‹¨ ì‹œì‘
- GET /gait-analysis/diagnosis/status/{diagnosisId}: ìƒíƒœ í™•ì¸
- ê¸°ì¡´ test_optimized_nodes_pipeline() ê²°ê³¼ë¥¼ result í•„ë“œë¡œ ë˜í•‘

Author: AI Assistant
Date: 2025-01-18
"""

import os
import uuid
import asyncio
import concurrent.futures
import time
import json
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, Any, Optional
from pathlib import Path
import threading
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
import uvicorn

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
import sys
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# ë­ê·¸ë˜í”„ ë…¸ë“œ imports (ìµœì¢… ë°°í¬ìš©)
from langgraph_nodes.graph_state import GraphState
from langgraph_nodes.data_processing_nodes import ReceiveRequestNode, FileMetadataNode, DownloadCsvNode, FilterDataNode
from langgraph_nodes.ai_model_nodes import PredictPhasesNode, PredictStrideNode
from langgraph_nodes.metrics_nodes import CalcMetricsNode, StoreMetricsNode
from langgraph_nodes.rag_diagnosis_nodes import ComposePromptNode, RagDiagnosisNode, StoreDiagnosisNode
from langgraph_nodes.response_nodes import FormatResponseNode

# ===== ê¸€ë¡œë²Œ ë…¸ë“œ ì¸ìŠ¤í„´ìŠ¤ (ìŠ¤ë§ˆíŠ¸ ì´ˆê¸°í™” ì‹œìŠ¤í…œ) =====
print("ğŸ”§ ì„œë²„ ì¤€ë¹„ ì¤‘...")

# ì´ˆê¸°í™” ìƒíƒœ íŒŒì¼ ê²½ë¡œ
INITIALIZATION_FILE = Path(__file__).parent / ".nodes_initialized"

# ë…¸ë“œ ì¸ìŠ¤í„´ìŠ¤ë“¤ì„ Noneìœ¼ë¡œ ì´ˆê¸°í™”
receive_request_node = None
file_metadata_node = None
download_csv_node = None
filter_data_node = None
predict_phases_node = None
predict_stride_node = None
calc_metrics_node = None
store_metrics_node = None
compose_prompt_node = None
rag_diagnosis_node = None
store_diagnosis_node = None
format_response_node = None

# ì´ˆê¸°í™” ì™„ë£Œ í”Œë˜ê·¸
_nodes_initialized = False
_initialization_lock = threading.Lock()

def is_already_initialized() -> bool:
    """ì´ì „ì— ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
    if not INITIALIZATION_FILE.exists():
        return False
    
    try:
        # íŒŒì¼ì´ 24ì‹œê°„ ì´ë‚´ì— ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸ (ë„ˆë¬´ ì˜¤ë˜ëœ ì´ˆê¸°í™”ëŠ” ë¬´íš¨)
        file_age = time.time() - INITIALIZATION_FILE.stat().st_mtime
        if file_age > 24 * 3600:  # 24ì‹œê°„
            print("ğŸ”„ ì´ˆê¸°í™” íŒŒì¼ì´ ì˜¤ë˜ë˜ì–´ ì¬ì´ˆê¸°í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            INITIALIZATION_FILE.unlink()  # ì˜¤ë˜ëœ íŒŒì¼ ì‚­ì œ
            return False
        
        return True
    except Exception:
        return False

def mark_initialization_complete():
    """ì´ˆê¸°í™” ì™„ë£Œ ìƒíƒœë¥¼ íŒŒì¼ì— ì €ì¥"""
    try:
        INITIALIZATION_FILE.write_text(f"initialized_at:{time.time()}\n")
        print(f"âœ… ì´ˆê¸°í™” ìƒíƒœ ì €ì¥: {INITIALIZATION_FILE}")
    except Exception as e:
        print(f"âš ï¸ ì´ˆê¸°í™” ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {e}")

def initialize_nodes_startup():
    """ì„œë²„ ì‹œì‘ì‹œ ë…¸ë“œ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ)"""
    global _nodes_initialized
    global receive_request_node, file_metadata_node, download_csv_node, filter_data_node
    global predict_phases_node, predict_stride_node, calc_metrics_node, store_metrics_node
    global compose_prompt_node, rag_diagnosis_node, store_diagnosis_node, format_response_node
    
    # ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if is_already_initialized():
        print("âš¡ ì´ì „ ì´ˆê¸°í™” ê°ì§€ - ë¹ ë¥¸ ì‹œì‘ ëª¨ë“œ")
        print("ğŸ”§ ë…¸ë“œ ì¸ìŠ¤í„´ìŠ¤ ë¹ ë¥¸ ì´ˆê¸°í™” ì¤‘...")
        
        # ë¹ ë¥¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (RAGëŠ” ì´ë¯¸ ì¤€ë¹„ë¨)
        receive_request_node = ReceiveRequestNode()
        file_metadata_node = FileMetadataNode()
        download_csv_node = DownloadCsvNode()
        filter_data_node = FilterDataNode()
        predict_phases_node = PredictPhasesNode()
        predict_stride_node = PredictStrideNode()
        calc_metrics_node = CalcMetricsNode()
        store_metrics_node = StoreMetricsNode()
        compose_prompt_node = ComposePromptNode()
        rag_diagnosis_node = RagDiagnosisNode()  # ChromaDB ì´ë¯¸ ì¤€ë¹„ë¨
        store_diagnosis_node = StoreDiagnosisNode()
        format_response_node = FormatResponseNode()
        
        _nodes_initialized = True
        print("âœ… ë¹ ë¥¸ ì‹œì‘ ì™„ë£Œ! (3ì´ˆ)")
        return
    
    # ìµœì´ˆ ì´ˆê¸°í™” (ì‹œê°„ì´ ê±¸ë¦¼)
    print("ğŸš€ ìµœì´ˆ ì„œë²„ ì‹œì‘ - ì „ì²´ ì´ˆê¸°í™” ì§„í–‰ ì¤‘...")
    print("â° ì˜ˆìƒ ì†Œìš” ì‹œê°„: 30-60ì´ˆ (RAG ì‹œìŠ¤í…œ ì¤€ë¹„)")
    
    with _initialization_lock:
        print("ğŸ”§ ë…¸ë“œ ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™” ì‹œì‘...")
        
        # LLM ì œê±°ëœ 8ê°œ ë…¸ë“œ (ë¹ ë¥¸ ì´ˆê¸°í™”)
        receive_request_node = ReceiveRequestNode()
        file_metadata_node = FileMetadataNode()
        download_csv_node = DownloadCsvNode()
        filter_data_node = FilterDataNode()
        predict_phases_node = PredictPhasesNode()
        predict_stride_node = PredictStrideNode()
        calc_metrics_node = CalcMetricsNode()
        store_metrics_node = StoreMetricsNode()
        
        print("âš¡ 8ê°œ LLM-free ë…¸ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # LLM ì‚¬ìš© 4ê°œ ë…¸ë“œ (RAG ì´ˆê¸°í™” í¬í•¨)
        print("ğŸ§  RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘... (ChromaDB + ì˜ë£Œ ë…¼ë¬¸ ì¤€ë¹„)")
        compose_prompt_node = ComposePromptNode()
        rag_diagnosis_node = RagDiagnosisNode()  # ì—¬ê¸°ì„œ ChromaDB ì´ˆê¸°í™”
        store_diagnosis_node = StoreDiagnosisNode()
        format_response_node = FormatResponseNode()
        
        _nodes_initialized = True
        
        # ì´ˆê¸°í™” ì™„ë£Œ ìƒíƒœ ì €ì¥
        mark_initialization_complete()
        print("âœ… ìµœì´ˆ ì „ì²´ ì´ˆê¸°í™” ì™„ë£Œ! ë‹¤ìŒ ì¬ì‹œì‘ë¶€í„°ëŠ” ë¹ ë¥´ê²Œ ì‹œì‘ë©ë‹ˆë‹¤.")

def initialize_nodes_once():
    """API ìš”ì²­ì‹œ ë…¸ë“œ ì´ˆê¸°í™” í™•ì¸ (Fallback)"""
    if not _nodes_initialized:
        print("âš ï¸ ë…¸ë“œê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ - ê¸´ê¸‰ ì´ˆê¸°í™” ì‹¤í–‰")
        initialize_nodes_startup()

# ì„œë²„ ì‹œì‘ì‹œ ì¦‰ì‹œ ì´ˆê¸°í™” ì‹¤í–‰
initialize_nodes_startup()

print("âœ… ì„œë²„ ì¤€ë¹„ ì™„ë£Œ! (ìŠ¤ë§ˆíŠ¸ ì´ˆê¸°í™” ì‹œìŠ¤í…œ)")

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Gait Analysis API",
    description="ë°±ì—”ë“œ ë˜í•‘ ê°€ì´ë“œì— ë§ì¶˜ ë¹„ë™ê¸° ë³´í–‰ ë¶„ì„ API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"],
)

# ===== ë°ì´í„° ëª¨ë¸ ì •ì˜ =====

class UserInfo(BaseModel):
    name: str = Field(..., description="ì‚¬ìš©ì ì´ë¦„")
    height: int = Field(..., ge=100, le=250, description="í‚¤ (cm)")
    gender: str = Field(..., pattern="^(male|female|other)$", description="ì„±ë³„")

class GaitData(BaseModel):
    walkingTime: int = Field(..., description="ë³´í–‰ ì‹œê°„ (ì´ˆ)")
    steps: int = Field(..., description="ê±¸ìŒ ìˆ˜")
    distance: int = Field(..., description="ê±°ë¦¬ (m)")

class DiagnosisRequest(BaseModel):
    userInfo: UserInfo
    gaitData: GaitData
    timestamp: str = Field(..., description="ìš”ì²­ ì‹œê°„ (ISO 8601)")

class DiagnosisResponse(BaseModel):
    success: bool
    data: Dict[str, Any]

# ===== ìƒíƒœ ê´€ë¦¬ (ë©”ëª¨ë¦¬ ê¸°ë°˜) =====

# ì§„ë‹¨ ìƒíƒœ ì €ì¥ì†Œ (ì¶”í›„ DBë¡œ êµì²´ ê°€ëŠ¥)
diagnosis_store: Dict[str, Dict[str, Any]] = {}

# ìŠ¤ë ˆë“œ ì•ˆì „ì„±ì„ ìœ„í•œ ë½
diagnosis_store_lock = threading.Lock()

# ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹¤í–‰ê¸° (ë” ë§ì€ ì›Œì»¤ë¡œ í™•ì¥)
executor = concurrent.futures.ThreadPoolExecutor(max_workers=5, thread_name_prefix="langgraph")

def generate_diagnosis_id() -> str:
    """ê³ ìœ í•œ ì§„ë‹¨ ID ìƒì„±"""
    return f"diagnosis_{uuid.uuid4().hex[:8]}"

def create_diagnosis_record(request: DiagnosisRequest) -> str:
    """ìƒˆë¡œìš´ ì§„ë‹¨ ë ˆì½”ë“œ ìƒì„± (ìŠ¤ë ˆë“œ ì•ˆì „)"""
    diagnosis_id = generate_diagnosis_id()
    now = datetime.now()
    
    record = {
        "diagnosisId": diagnosis_id,
        "userId": request.userInfo.name,  # nameì„ userIdë¡œ ì‚¬ìš©
        "status": "processing",
        "progress": 0,
        "requestedAt": now.isoformat(),
        "estimatedCompletionTime": (now + timedelta(minutes=5)).isoformat(),
        "message": "ë­ê·¸ë˜í”„ ì§„ë‹¨ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "request_data": request.dict(),
        "result": None,
        "error": None,
        "current_stage": None,
        "stage_details": None,
        "created_at": now.timestamp(),  # ìƒì„± ì‹œê°„ ì¶”ê°€
        "last_updated": now.timestamp()  # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„
    }
    
    # ìŠ¤ë ˆë“œ ì•ˆì „í•˜ê²Œ ì €ì¥
    with diagnosis_store_lock:
        diagnosis_store[diagnosis_id] = record
    
    return diagnosis_id

def update_diagnosis_status(diagnosis_id: str, status: str, progress: int = None, message: str = None, result: Any = None, error: str = None, current_stage: str = None, stage_details: str = None):
    """ì§„ë‹¨ ìƒíƒœ ì—…ë°ì´íŠ¸ (ìŠ¤ë ˆë“œ ì•ˆì „)"""
    with diagnosis_store_lock:
        if diagnosis_id not in diagnosis_store:
            return False
        
        record = diagnosis_store[diagnosis_id]
        record["status"] = status
        record["last_updated"] = datetime.now().timestamp()  # ì—…ë°ì´íŠ¸ ì‹œê°„ ê°±ì‹ 
        
        if progress is not None:
            record["progress"] = progress
        if message is not None:
            record["message"] = message
        if result is not None:
            record["result"] = result
        if error is not None:
            record["error"] = error
        if current_stage is not None:
            record["current_stage"] = current_stage
        if stage_details is not None:
            record["stage_details"] = stage_details
        
        # ì™„ë£Œ ì‹œ estimatedCompletionTimeì„ Noneìœ¼ë¡œ ì„¤ì •
        if status == "completed":
            record["estimatedCompletionTime"] = None
            record["progress"] = 100
            record["message"] = "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
        elif status == "failed":
            record["estimatedCompletionTime"] = None
            record["message"] = f"ë¶„ì„ ì‹¤íŒ¨: {error}"
        
        return True

# ===== ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… í•¨ìˆ˜ =====

def run_langgraph_pipeline_with_progress(diagnosis_id: str, request: DiagnosisRequest):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìµœì í™”ëœ 12ë‹¨ê³„ ë­ê·¸ë˜í”„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    
    ìµœì¢… ë°°í¬ìš© - test_actual_nodes_pipeline.py ë¡œì§ ì™„ì „ í†µí•©
    - 67% ìµœì í™”: 8/12 ë…¸ë“œ LLM ì œê±° (ìˆœìˆ˜ Python + ë”¥ëŸ¬ë‹) 
    - 4/12 ë…¸ë“œ LLM ì‚¬ìš© (ì§„ë‹¨ ê´€ë ¨)
    - í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜: ë°ì´í„° ì²˜ë¦¬ ì¦‰ì‹œ ì‹¤í–‰ + ì§„ë‹¨ë§Œ LLM ëŒ€ê¸°
    """
    pipeline_start_time = time.time()
    llm_call_count = 0
    
    try:
        print(f"ğŸš€ ìµœì í™”ëœ ë­ê·¸ë˜í”„ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {diagnosis_id}")
        
        # ì‹œì‘ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
        update_diagnosis_status(
            diagnosis_id, 
            "processing", 
            progress=5,
            message="AIê°€ ë³´í–‰ íŒ¨í„´ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
            current_stage="initializing"
        )
        
        # ==== ìµœì í™”ëœ ë­ê·¸ë˜í”„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ====
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì • - ìƒˆë¡œìš´ ì…ë ¥ ì‹œìŠ¤í…œ (user_id, height_cm, gender)
        update_diagnosis_status(diagnosis_id, "processing", 10, "ì´ˆê¸° ìƒíƒœ ì„¤ì • ì¤‘...", current_stage="setup")
        
        initial_state = GraphState()
        initial_state.update({
            "user_id": request.userInfo.name,  # ì‚¬ìš©ì ì´ë¦„ì„ user_idë¡œ ì‚¬ìš©
            "height_cm": float(request.userInfo.height),
            "gender": request.userInfo.gender,
            "session_id": diagnosis_id,
            "timestamp": request.timestamp
        })
        
        current_state = initial_state.copy()
        
        print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸ ì„¸ì…˜: {current_state['session_id']}")
        print(f"ğŸ‘¤ ì‚¬ìš©ì ID: {current_state['user_id']}")
        print(f"ğŸ“ í‚¤: {current_state['height_cm']}cm")
        print(f"ğŸ‘« ì„±ë³„: {current_state['gender']}")
        
        # 12ë‹¨ê³„ ìµœì í™”ëœ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì‚¬ì „ ì´ˆê¸°í™”ëœ ë…¸ë“œ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©)
        pipeline_stages = [
            # LLM ì œê±°ëœ 8ê°œ ë…¸ë“œ (67% ìµœì í™”) - ì‚¬ì „ ì´ˆê¸°í™”ëœ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
            (receive_request_node, "ì…ë ¥ ê²€ì¦", 15, "receiverequestnode", False),
            (file_metadata_node, "Storage íŒŒì¼ ê²€ìƒ‰", 25, "filemetadatanode", False), 
            (download_csv_node, "ë°ì´í„° ë‹¤ìš´ë¡œë“œ", 35, "downloadcsvnode", False),
            (filter_data_node, "Butterworth í•„í„°ë§ + íŠ¸ë¦¬ë°", 45, "filterdatanode", False),
            (predict_phases_node, "ë”¥ëŸ¬ë‹ ë³´í–‰ ë‹¨ê³„ ì˜ˆì¸¡", 55, "predictphasesnode", False),
            (predict_stride_node, "ë”¥ëŸ¬ë‹ ë³´í­/ì†ë„ ì˜ˆì¸¡", 65, "predictstridenode", False),
            (calc_metrics_node, "12ê°œ ë³´í–‰ ì§€í‘œ ê³„ì‚°", 75, "calcmetricsnode", False),
            (store_metrics_node, "ì§€í‘œ ì €ì¥", 80, "storemetricsnode", False),
            
            # LLM ì‚¬ìš© 4ê°œ ë…¸ë“œ (ì§„ë‹¨ ì „ìš©) - ì‚¬ì „ ì´ˆê¸°í™”ëœ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
            (compose_prompt_node, "ì§„ë‹¨ í”„ë¡¬í”„íŠ¸ êµ¬ì„±", 85, "composepromptnode", True),
            (rag_diagnosis_node, "RAG ê¸°ë°˜ ì˜ë£Œ ì§„ë‹¨", 90, "ragdiagnosisnode", True),
            (store_diagnosis_node, "ì§„ë‹¨ ê²°ê³¼ ì €ì¥", 95, "storediagnosisnode", True),
            (format_response_node, "ìµœì¢… ì‘ë‹µ ìƒì„±", 100, "formatresponsenode", True)
        ]
        
        for i, (node_instance, description, progress, stage_name, uses_llm) in enumerate(pipeline_stages):
            step_start = time.time()
            
            try:
                # ìƒíƒœ ì—…ë°ì´íŠ¸
                status = "analyzing" if progress < 80 else "generating_report"
                update_diagnosis_status(
                    diagnosis_id, 
                    status,
                    progress, 
                    f"{description} ì¤‘...",
                    current_stage=stage_name
                )
                
                print(f"\n{'='*80}")
                node_type = "ğŸ¤– LLM ì‚¬ìš©" if uses_llm else "âš¡ LLM ì œê±°"
                print(f"{i+1}ï¸âƒ£ STEP {i+1}: {node_instance.__class__.__name__} - {description} ({node_type})")
                print(f"{'='*80}")
                
                # íŠ¹ë³„ ì²˜ë¦¬ë“¤
                if node_instance is store_metrics_node:
                    current_state['date'] = datetime.now().strftime('%Y-%m-%d')
                
                # LLM í˜¸ì¶œ ì¶”ì  (ë°°í¬ìš©ì—ì„œëŠ” ì‹¤ì œë¡œ ì¶”ì í•˜ì§€ ì•Šì§€ë§Œ ë¡œê·¸ìš©)
                if uses_llm:
                    llm_call_count += 1
                    print(f"   ğŸ§  LLM Call #{llm_call_count} - {description}")
                else:
                    print(f"   âš¡ ìˆœìˆ˜ Python/ë”¥ëŸ¬ë‹ ì‹¤í–‰ - LLM ì—†ìŒ")
                
                # ë…¸ë“œ ì‹¤í–‰
                print(f"ğŸ”„ {description} ì‹¤í–‰ ì¤‘...")
                current_state = node_instance.execute(current_state)
                step_time = time.time() - step_start
                
                # ì—ëŸ¬ ì²´í¬
                if current_state.get('error'):
                    raise Exception(f"{node_instance.__class__.__name__} ì‹¤í–‰ ì‹¤íŒ¨: {current_state['error']}")
                    
                # ì„±ê³µ ë¡œê·¸ + ìƒì„¸ ì •ë³´
                print(f"âœ… {node_instance.__class__.__name__} ì™„ë£Œ! ({step_time:.2f}ì´ˆ)")
                
                # ë‹¨ê³„ë³„ ì„¸ë¶€ ì •ë³´ ì¶œë ¥ (ì¤‘ìš”í•œ ê²ƒë“¤ë§Œ)
                if node_instance is download_csv_node:
                    csv_path = current_state.get('raw_csv_path')
                    if csv_path:
                        df = pd.read_csv(csv_path)
                        print(f"   ğŸ“Š ë‹¤ìš´ë¡œë“œëœ ë°ì´í„°: {len(df):,}ê°œ ë ˆì½”ë“œ")
                
                elif node_instance is filter_data_node:
                    filtered_path = current_state.get('filtered_csv_path')
                    if filtered_path:
                        df_filtered = pd.read_csv(filtered_path)
                        print(f"   ğŸ“Š í•„í„°ë§ëœ ë°ì´í„°: {len(df_filtered):,}ê°œ ë ˆì½”ë“œ")
                
                elif node_instance is calc_metrics_node:
                    gait_metrics = current_state.get('gait_metrics')
                    if gait_metrics:
                        print(f"   ğŸ“Š ê³„ì‚°ëœ ë³´í–‰ ì§€í‘œ:")
                        print(f"      â±ï¸ í‰ê·  ë³´í–‰ì‹œê°„: {gait_metrics.get('avg_stride_time', 0):.3f}ì´ˆ")
                        print(f"      ğŸ“ í‰ê·  ë³´í­: {gait_metrics.get('avg_stride_length', 0):.3f}m")
                        print(f"      ğŸƒ í‰ê·  ì†ë„: {gait_metrics.get('avg_walking_speed', 0):.3f}m/s")
                
                elif node_instance is rag_diagnosis_node:
                    diagnosis_result = current_state.get('diagnosis_result')
                    if diagnosis_result:
                        print(f"   ğŸ¥ ì§„ë‹¨ ê²°ê³¼ ê¸¸ì´: {len(diagnosis_result):,} ë¬¸ì")
                        preview = diagnosis_result[:150] + "..." if len(diagnosis_result) > 150 else diagnosis_result
                        print(f"   ğŸ‘¨â€âš•ï¸ ì§„ë‹¨ ë¯¸ë¦¬ë³´ê¸°: {preview}")
                
            except Exception as e:
                step_time = time.time() - step_start
                print(f"âŒ {node_instance.__class__.__name__} ì‹¤íŒ¨: {e} ({step_time:.2f}ì´ˆ)")
                update_diagnosis_status(
                    diagnosis_id, 
                    "failed", 
                    progress, 
                    error=f"{description} ì‹¤íŒ¨: {str(e)}"
                )
                return
        
        # ==== ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ ====
        total_time = time.time() - pipeline_start_time
        
        # ë°±ì—”ë“œ ë˜í•‘ ê°€ì´ë“œì— ë§ëŠ” ê²°ê³¼ êµ¬ì¡°ë¡œ ë˜í•‘
        print(f"\nğŸ” extract_final_result í˜¸ì¶œ ì „ current_state í‚¤ë“¤:")
        print(f"   - ì „ì²´ í‚¤: {list(current_state.keys())}")
        if 'final_response' in current_state:
            print(f"   - final_response íƒ€ì…: {type(current_state['final_response'])}")
            if isinstance(current_state['final_response'], dict):
                print(f"   - final_response í‚¤ë“¤: {list(current_state['final_response'].keys())}")
        
        langgraph_result = extract_final_result(current_state)
        
        # ğŸ” ìµœì¢… ì‘ë‹µ ì½˜ì†” ì¶œë ¥ (ìš”ì²­ì‚¬í•­)
        print(f"\n{'='*80}")
        print("ğŸ“‹ ìµœì¢… ì‘ë‹µ ê²°ê³¼ (ì½˜ì†” ì¶œë ¥)")
        print("="*80)
        print(f"ğŸ“Š ì§„ë‹¨ ID: {diagnosis_id}")
        print(f"ğŸ‘¤ ì‚¬ìš©ì: {langgraph_result.get('userId', 'unknown')}")
        print(f"â° ë¶„ì„ ì‹œê°„: {langgraph_result.get('analyzedAt', 'unknown')}")
        print(f"ğŸ“ˆ ì ìˆ˜: {langgraph_result.get('score', 'N/A')}")
        print(f"ğŸ¥ ìƒíƒœ: {langgraph_result.get('status', 'unknown')}")
        print(f"âš ï¸ ìœ„í—˜ë„: {langgraph_result.get('riskLevel', 'unknown')}")
        
        # ì§€í‘œ ì •ë³´ ì¶œë ¥
        indicators = langgraph_result.get('indicators', [])
        print(f"\nğŸ“Š ë³´í–‰ ì§€í‘œ ({len(indicators)}ê°œ):")
        for i, indicator in enumerate(indicators, 1):
            print(f"   {i}. {indicator.get('name', 'N/A')}: {indicator.get('value', 'N/A')}")
            print(f"      ìƒíƒœ: {indicator.get('status', 'N/A')} - {indicator.get('result', 'N/A')}")
        
        # ì§ˆë³‘ ì •ë³´ ì¶œë ¥
        diseases = langgraph_result.get('diseases', [])
        print(f"\nğŸ¥ ì§ˆë³‘ ì •ë³´ ({len(diseases)}ê°œ):")
        if diseases:
            for i, disease in enumerate(diseases, 1):
                print(f"   {i}. {disease}")
        else:
            print("   ì§ˆë³‘ ì •ë³´ ì—†ìŒ")
        
        # ìƒì„¸ ë¦¬í¬íŠ¸ ì¶œë ¥
        detailed_report = langgraph_result.get('detailedReport', {})
        print(f"\nğŸ“‹ ìƒì„¸ ë¦¬í¬íŠ¸:")
        print(f"   ì œëª©: {detailed_report.get('title', 'N/A')}")
        report_content = detailed_report.get('content', 'N/A')
        if isinstance(report_content, str):
            # ë„ˆë¬´ ê¸¸ë©´ ì²˜ìŒ 300ìë§Œ ì¶œë ¥
            content_preview = report_content[:300] + "..." if len(report_content) > 300 else report_content
            print(f"   ë‚´ìš©: {content_preview}")
        else:
            print(f"   ë‚´ìš© (ê°ì²´): {type(report_content)} - {report_content}")
        
        print(f"\nğŸ¯ ì™„ì „í•œ ìµœì¢… ì‘ë‹µ êµ¬ì¡°:")
        import json
        try:
            formatted_result = json.dumps(langgraph_result, indent=2, ensure_ascii=False)
            print(formatted_result)
        except Exception as e:
            print(f"JSON ë³€í™˜ ì‹¤íŒ¨: {e}")
            print(f"Raw result: {langgraph_result}")
        
        print("="*80)
        print("âœ… ìµœì¢… ì‘ë‹µ ì½˜ì†” ì¶œë ¥ ì™„ë£Œ!")
        print("="*80)
        
        update_diagnosis_status(
            diagnosis_id,
            "completed",
            100,
            "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!",
            result=langgraph_result,
            current_stage="completed"
        )
        
        # ìµœì¢… ì„±ê³¼ ìš”ì•½
        print(f"\n{'='*80}")
        print("ğŸ‰ ì™„ì „í•œ End-to-End ìµœì í™”ëœ LangGraph íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print("="*80)
        
        print(f"ğŸ“Š íŒŒì´í”„ë¼ì¸ ì„±ê³¼:")
        print(f"   ğŸš€ ì´ LLM í˜¸ì¶œ: {llm_call_count}íšŒ (ì˜ˆìƒ: 4íšŒ)")
        print(f"   â±ï¸ ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"   ğŸ¯ ìµœì í™” êµ¬ì¡°: 8/12 ë…¸ë“œ LLM ì œê±° (67% ìµœì í™”)")
        print(f"   ğŸ’¡ í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜: ë°ì´í„° ì²˜ë¦¬ëŠ” ìˆœìˆ˜ Python, ì§„ë‹¨ì€ LLM")
        
        print(f"\nğŸ—ï¸ ìµœì í™”ëœ í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜:")
        print(f"   ğŸ“Š ì…ë ¥ ì‹œìŠ¤í…œ: (user_id, height_cm, gender)")
        print(f"   ğŸ—„ï¸ ë°ì´í„° ì†ŒìŠ¤: Supabase Storage (CSV íŒŒì¼)")
        print(f"   ğŸ¤– ë°ì´í„° ì²˜ë¦¬: ìˆœìˆ˜ Python + ë”¥ëŸ¬ë‹ (LLM ì—†ìŒ)")
        print(f"   ğŸ§  ì˜ë£Œ ì§„ë‹¨: RAG + LLM (ChromaDB + ì˜ë£Œ ë¬¸í—Œ)")
        print(f"   âš¡ ì„±ëŠ¥: ë°ì´í„° ì²˜ë¦¬ ì¦‰ì‹œ ì‹¤í–‰, ì§„ë‹¨ë§Œ LLM ëŒ€ê¸°")
        
        print(f"ğŸ‰ ë­ê·¸ë˜í”„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {diagnosis_id}")
        
    except Exception as e:
        print(f"ğŸ’¥ ë­ê·¸ë˜í”„ íŒŒì´í”„ë¼ì¸ ì „ì²´ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        update_diagnosis_status(
            diagnosis_id,
            "failed",
            error=f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}"
        )


def extract_final_result(final_state: dict) -> dict:
    """
    2-Stage RAG ì‹œìŠ¤í…œì—ì„œ ìƒì„±ëœ ì™„ë²½í•œ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì¶”ì¶œ
    
    2-Stage RAGê°€ ì´ë¯¸ ì™„ë²½í•œ êµ¬ì¡°ë¥¼ ë§Œë“¤ì–´ì£¼ë¯€ë¡œ ë‹¨ìˆœíˆ ì¶”ì¶œë§Œ í•¨:
    - Stage 1: 15ê°œ ê°œë³„ ì§€í‘œ ë¶„ì„ (indicators ë°°ì—´)
    - Stage 2: ì¢…í•© ì§„ë‹¨ (score, diseases, detailedReport)
    """
    try:
        print(f"ğŸ” final_state í‚¤ ë¶„ì„: {list(final_state.keys())}")
        
        # 1ìˆœìœ„: ìƒˆë¡œìš´ diagnosis_result êµ¬ì¡° ì§ì ‘ ì‚¬ìš© (2-Stage RAG ì™„ì„±í’ˆ)
        if 'diagnosis_result' in final_state:
            diagnosis_result = final_state['diagnosis_result']
            print(f"âœ… diagnosis_result ë°œê²¬ - íƒ€ì…: {type(diagnosis_result)}")
            
            if isinstance(diagnosis_result, dict):
                print(f"ğŸ“‹ diagnosis_result í‚¤ë“¤: {list(diagnosis_result.keys())}")
                
                # 2-Stage RAG ê²°ê³¼ ê²€ì¦
                indicators = diagnosis_result.get('indicators', [])
                score = diagnosis_result.get('score', 0)
                diseases = diagnosis_result.get('diseases', [])
                detailed_report = diagnosis_result.get('detailedReport', {})
                
                print(f"ğŸ¯ 2-Stage RAG ì™„ì„±í’ˆ í™•ì¸:")
                print(f"   - indicators: {len(indicators)}ê°œ (Stage 1)")
                print(f"   - score: {score} (Stage 2)")
                print(f"   - diseases: {len(diseases)}ê°œ (Stage 2)")
                print(f"   - detailedReport: {'ìˆìŒ' if detailed_report else 'ì—†ìŒ'} (Stage 2)")
                
                # í•„ìš”í•œ ë©”íƒ€ë°ì´í„°ë§Œ ì¶”ê°€
                result = diagnosis_result.copy()
                if "userId" not in result:
                    result["userId"] = final_state.get('user_id', 'unknown')
                if "analyzedAt" not in result:
                    result["analyzedAt"] = datetime.now().isoformat()
                
                # diseases probability í˜•ì‹ ê²€ì¦ (0.0-1.0 ë²”ìœ„)
                if diseases:
                    for disease in diseases:
                        if 'probability' in disease and disease['probability'] > 1.0:
                            disease['probability'] = disease['probability'] / 100.0
                
                print(f"âœ… 2-Stage RAG ì™„ì„±í’ˆ ê·¸ëŒ€ë¡œ ì‚¬ìš©!")
                return result
        
        # 2ìˆœìœ„: FormatResponseNodeì˜ response ê²°ê³¼ ì‚¬ìš©
        if 'response' in final_state:
            response_data = final_state['response']
            print(f"âœ… state['response'] ë°œê²¬ - íƒ€ì…: {type(response_data)}")
            
            if isinstance(response_data, dict):
                print(f"ğŸ“‹ response í‚¤ë“¤: {list(response_data.keys())}")
                
                # FormatResponseNode í‘œì¤€ ì¶œë ¥ í™•ì¸
                if 'indicators' in response_data and 'score' in response_data:
                    indicators = response_data.get('indicators', [])
                    score = response_data.get('score', 0)
                    print(f"ğŸ¯ FormatResponseNode ì™„ì„±í’ˆ: {len(indicators)}ê°œ ì§€í‘œ, ì ìˆ˜ {score}")
                    return response_data
                
                # {success: true, data: {...}} í˜•íƒœì¸ ê²½ìš°
                elif 'success' in response_data and 'data' in response_data:
                    data_section = response_data['data']
                    if isinstance(data_section, dict) and 'indicators' in data_section:
                        print(f"ğŸ¯ FormatResponseNode ë˜í•‘ëœ ë°ì´í„° ì‚¬ìš©")
                        return data_section
            
            # JSON ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±
            elif isinstance(response_data, str):
                print(f"ğŸ” JSON ë¬¸ìì—´ íŒŒì‹± ì‹œë„ (ê¸¸ì´: {len(response_data)})")
                try:
                    parsed = json.loads(response_data)
                    if isinstance(parsed, dict) and 'indicators' in parsed:
                        print(f"âœ… JSON íŒŒì‹± ì„±ê³µ - ì™„ì„±í’ˆ ì‚¬ìš©")
                        return parsed
                except Exception as parse_error:
                    print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {parse_error}")
        
        # 3ìˆœìœ„: final_response (ë ˆê±°ì‹œ í˜¸í™˜ì„±)
        elif 'final_response' in final_state:
            final_response = final_state['final_response']
            print(f"âš ï¸ state['final_response'] ì‚¬ìš© (ë ˆê±°ì‹œ) - íƒ€ì…: {type(final_response)}")
            
            if isinstance(final_response, dict) and 'indicators' in final_response:
                return final_response
        
        # ìµœì¢… ë°±ì—…: ê¸°ë³¸ ì‘ë‹µ (2-Stage RAG ì‹¤íŒ¨ ì‹œì—ë§Œ)
        print(f"âš ï¸ 2-Stage RAG ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ - ê¸°ë³¸ ì‘ë‹µ ìƒì„±")
        user_id = final_state.get('user_id', 'unknown')
        
        return {
            "userId": user_id,
            "score": 75,
            "status": "ë³´í–‰ ë¶„ì„ ì™„ë£Œ",
            "riskLevel": "ì •ìƒ ë‹¨ê³„",
            "analyzedAt": datetime.now().isoformat(),
            "indicators": [
                {
                    "id": "fallback",
                    "name": "ê¸°ë³¸ ë¶„ì„",
                    "value": "ì™„ë£Œ",
                    "status": "normal",
                    "description": "ê¸°ë³¸ì ì¸ ë³´í–‰ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                    "result": "ì¶”ê°€ì ì¸ ë¶„ì„ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                }
            ],
            "diseases": [
                {
                    "id": "general",
                    "name": "ì¼ë°˜ì  ìœ„í—˜ë„",
                    "probability": 0.25,
                    "status": "ì •ìƒ ë²”ìœ„",
                    "trend": "stable"
                }
            ],
            "detailedReport": {
                "title": "ë³´í–‰ ë¶„ì„ ê²°ê³¼",
                "content": "ê¸°ë³¸ì ì¸ ë³´í–‰ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë” ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
            }
        }
        
    except Exception as e:
        print(f"âŒ extract_final_result ì „ì²´ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        
        # ìµœì¢… ë°±ì—…
        return {
            "userId": final_state.get('user_id', 'unknown'),
            "score": 75,
            "status": "ë³´í–‰ ë¶„ì„ ì™„ë£Œ",
            "riskLevel": "ì •ìƒ ë‹¨ê³„", 
            "analyzedAt": datetime.now().isoformat(),
            "indicators": [],
            "diseases": [
                {"id": "error_fallback", "name": "ë¶„ì„ ì˜¤ë¥˜", "probability": 0.0, "status": "í™•ì¸ í•„ìš”", "trend": "unknown"}
            ],
            "detailedReport": {
                "title": "ë³´í–‰ ë¶„ì„ ê²°ê³¼",
                "content": "ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
            }
        }


# 2-Stage RAG ì‹œìŠ¤í…œì´ ì™„ë²½í•œ ê²°ê³¼ë¥¼ ìƒì„±í•˜ë¯€ë¡œ í—¬í¼ í•¨ìˆ˜ë“¤ ì œê±°ë¨
# create_indicators_from_metrics, calculate_score_from_indicators ë“±ì€ ë” ì´ìƒ í•„ìš” ì—†ìŒ

async def run_langgraph_pipeline_async(diagnosis_id: str, request: DiagnosisRequest):
    """ë¹„ë™ê¸° ë˜í¼: ë°±ê·¸ë¼ìš´ë“œì—ì„œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    loop = asyncio.get_event_loop()
    await loop.run_in_executor(executor, run_langgraph_pipeline_with_progress, diagnosis_id, request)

# ===== API ì—”ë“œí¬ì¸íŠ¸ =====

@app.post("/gait-analysis/langgraph-diagnosis", response_model=DiagnosisResponse)
async def start_diagnosis(request: DiagnosisRequest, background_tasks: BackgroundTasks):
    """
    1ë‹¨ê³„: ì§„ë‹¨ ìš”ì²­ ì‹œì‘
    
    ë°±ì—”ë“œ ë˜í•‘ ê°€ì´ë“œì— ë”°ë¼ diagnosisIdë¥¼ ì¦‰ì‹œ ë°˜í™˜í•˜ê³ 
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë­ê·¸ë˜í”„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    """
    try:
        # ì²« ìš”ì²­ì‹œ ë…¸ë“œ ì´ˆê¸°í™” (Lazy Loading)
        initialize_nodes_once()
        
        # ì§„ë‹¨ ë ˆì½”ë“œ ìƒì„±
        diagnosis_id = create_diagnosis_record(request)
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë­ê·¸ë˜í”„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        background_tasks.add_task(run_langgraph_pipeline_async, diagnosis_id, request)
        
        # ì¦‰ì‹œ ì‘ë‹µ ë°˜í™˜
        response_data = {
            "diagnosisId": diagnosis_id,
            "userId": request.userInfo.name,
            "status": "processing",
            "requestedAt": diagnosis_store[diagnosis_id]["requestedAt"],
            "estimatedCompletionTime": diagnosis_store[diagnosis_id]["estimatedCompletionTime"],
            "message": "ë­ê·¸ë˜í”„ ì§„ë‹¨ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
        
        return DiagnosisResponse(success=True, data=response_data)
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì§„ë‹¨ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")

@app.get("/gait-analysis/diagnosis/status/{diagnosis_id}", response_model=DiagnosisResponse)
async def get_diagnosis_status(diagnosis_id: str):
    """
    2ë‹¨ê³„: ìƒíƒœ í™•ì¸ (ìŠ¤ë ˆë“œ ì•ˆì „)
    
    ë°±ì—”ë“œ ë˜í•‘ ê°€ì´ë“œì— ë”°ë¼:
    - ì§„í–‰ ì¤‘: status, progress, message ë°˜í™˜
    - ì™„ë£Œ ì‹œ: status="completed" + result í•„ë“œì— ë­ê·¸ë˜í”„ ë°ì´í„° ë˜í•‘
    """
    # ìŠ¤ë ˆë“œ ì•ˆì „í•˜ê²Œ ìƒíƒœ ì½ê¸°
    with diagnosis_store_lock:
        if diagnosis_id not in diagnosis_store:
            raise HTTPException(status_code=404, detail=f"ì§„ë‹¨ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {diagnosis_id}")
        
        # ê¹Šì€ ë³µì‚¬ë¡œ ì•ˆì „í•˜ê²Œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        record = diagnosis_store[diagnosis_id].copy()
    
    # ê¸°ë³¸ ì‘ë‹µ ë°ì´í„°
    response_data = {
        "diagnosisId": diagnosis_id,
        "status": record["status"],
        "progress": record["progress"],
        "estimatedCompletionTime": record.get("estimatedCompletionTime"),
        "message": record["message"]
    }
    
    # ì§„í–‰ ì¤‘ì¸ ê²½ìš° ì¶”ê°€ ì •ë³´
    if record["status"] in ["processing", "analyzing", "generating_report"]:
        response_data["currentStage"] = record.get("current_stage")
        response_data["stageDetails"] = record.get("stage_details")
    
    # ì™„ë£Œ ì‹œ result í•„ë“œ ì¶”ê°€ (í•µì‹¬!)
    if record["status"] == "completed" and record["result"]:
        response_data["result"] = record["result"]
    
    # ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì •ë³´
    elif record["status"] == "failed":
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": {
                    "code": "DIAGNOSIS_FAILED",
                    "message": record.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                }
            }
        )
    
    return DiagnosisResponse(success=True, data=response_data)

@app.get("/api/v1/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.get("/api/v1/pipeline-info")
async def pipeline_info():
    """ìµœì í™”ëœ 2-Stage RAG íŒŒì´í”„ë¼ì¸ ì •ë³´ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "pipeline": "Optimized 2-Stage RAG LangGraph gait analysis",
        "version": "5.0.0",
        "architecture": "2-stage_rag_hybrid",
        "stages": 12,
        "optimization": {
            "llm_reduction": "83% (10/12 nodes LLM-free)",
            "llm_free_stages": [
                "ReceiveRequestNode", "FileMetadataNode", "DownloadCsvNode", "FilterDataNode",
                "PredictPhasesNode", "PredictStrideNode", "CalcMetricsNode", "StoreMetricsNode",
                "ComposePromptNode", "StoreDiagnosisNode", "FormatResponseNode"
            ],
            "llm_powered_stages": [
                "RagDiagnosisNode (Stage 1 + Stage 2)"
            ]
        },
        "rag_system": {
            "type": "2-stage_analysis",
            "stage1": {
                "purpose": "Individual indicator analysis",
                "output": "15 gait indicators with status (normal/warning/danger)",
                "llm_calls": 1
            },
            "stage2": {
                "purpose": "Overall disease risk assessment",
                "output": "Disease probabilities + friendly medical report",
                "llm_calls": 1
            },
            "total_llm_calls": 2,
            "knowledge_base": "ChromaDB + Medical PDFs",
            "embedding_model": "sentence-transformers/all-MiniLM-L6-v2"
        },
        "processing": {
            "data_engine": "Pure Python + Deep Learning",
            "diagnosis_engine": "2-Stage RAG + LLM (ChromaDB)",
            "input_system": "(user_id, height_cm, gender)",
            "data_source": "Supabase Storage",
            "output_format": "Structured JSON (indicators + diseases + detailedReport)"
        },
        "performance": {
            "data_processing": "Immediate execution (no LLM wait)",
            "diagnosis_generation": "2-stage LLM-powered medical insights",
            "background_workers": executor._max_workers,
            "active_diagnoses": len([d for d in diagnosis_store.values() if d["status"] in ["processing", "analyzing", "generating_report"]])
        },
        "deployment": {
            "standalone": True,
            "dependencies_removed": ["test_actual_nodes_pipeline.py"],
            "embedded_pipeline": "Complete 12-stage logic integrated",
            "initialization": "Smart startup with ChromaDB pre-loading"
        }
    }

# ===== ì„œë²„ ì‹¤í–‰ =====

if __name__ == "__main__":
    print("\n" + "="*80)
    print("ğŸš€ 2-Stage RAG Gait Analysis FastAPI Server ì‹œì‘...")
    print("="*80)
    print("ğŸ“š API ë¬¸ì„œ: http://localhost:8000/docs")
    print("ğŸ¥ Health Check: http://localhost:8000/api/v1/health")
    print("ğŸ” Pipeline Info: http://localhost:8000/api/v1/pipeline-info")
    print("âš¡ ì§„ë‹¨ ì‹œì‘: POST http://localhost:8000/gait-analysis/langgraph-diagnosis")
    print("ğŸ“Š ìƒíƒœ í™•ì¸: GET http://localhost:8000/gait-analysis/diagnosis/status/{diagnosisId}")
    print()
    print("ğŸ¯ 2-Stage RAG í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸ v5.0.0")
    print("ğŸ“Š 83% ìµœì í™”: 10/12 ë…¸ë“œ LLM ì œê±° (ìˆœìˆ˜ Python + ë”¥ëŸ¬ë‹)")
    print("ğŸ§  2/12 ë…¸ë“œ LLM ì‚¬ìš© (2-Stage RAG ì§„ë‹¨ ì „ìš©)")
    print("ğŸ”¬ Stage 1: ê°œë³„ ì§€í‘œ ë¶„ì„ (15ê°œ ë³´í–‰ ì§€í‘œ)")
    print("ğŸ¥ Stage 2: ì¢…í•© ì§„ë‹¨ (ì§ˆë³‘ ìœ„í—˜ë„ + ì¹œí™”ì  ë¦¬í¬íŠ¸)")
    print("ğŸ—ï¸ ì™„ì „ ë…ë¦½í˜•: test_actual_nodes_pipeline.py ì˜ì¡´ì„± ì œê±°")
    print("âœ¨ êµ¬ì¡°í™”ëœ JSON ì‘ë‹µ: í™˜ê° ìµœì†Œí™” + API í˜¸í™˜ì„±")
    print(f"ğŸ”§ ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤: {executor._max_workers}ê°œ")
    print("âš¡ ë°ì´í„° ì²˜ë¦¬: ì¦‰ì‹œ ì‹¤í–‰ | ğŸ§  ì§„ë‹¨: 2-Stage RAG")
    print("ğŸ›¡ï¸ ìŠ¤ë ˆë“œ ì•ˆì „ì„±: ë™ì‹œì„± ì´ìŠˆ ë°©ì§€")
    print("ğŸ”„ í”„ë¡ íŠ¸ í´ë§: GET ìš”ì²­ ë¬´ì œí•œ ì§€ì›")
    print("ğŸš€ ì„œë²„ ì‹œì‘ ì´ˆê¸°í™”: ì™„ë£Œ (ChromaDB ì‚¬ì „ ë¡œë“œ)")
    print("ğŸ’¾ ChromaDB: ì˜ë£Œ ë…¼ë¬¸ ì„ë² ë”© ì¤€ë¹„ ì™„ë£Œ")
    print("="*80)
    print()
    
    uvicorn.run(
        "fastapi_server:app",
        host="127.0.0.1",
        port=8000,
        reload=False,  # ê°œë°œ ì¤‘ ìë™ ë¦¬ë¡œë”© ë¹„í™œì„±í™” (ì´ˆê¸°í™” ì¤‘ë³µ ë°©ì§€)
        log_level="info"
    ) 